{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们学习了通过最小二乘法求解回归模型，既可以求解线性回归，也可以扩展到非线性回归。最小二乘法是机器学习中的最基础的算法，这种求解损失函数最小值的思路可以延伸到更多的机器学习算法中，包括分类和聚类问题。\n",
    "\n",
    "但是求得的模型损失函数最小，模型就是最好吗？如何评估模型是不是好呢？这就是这一节要讨论的问题。\n",
    "\n",
    "我们知道，机器学习是关于算法的算法，根据输入的数据，生成 **模型**（model），这个模型可以接收新的输入数据，从而对未知的情况作出预测。生成模型的过程称为 **学习**（learning）或 **训练**（training），训练所使用的数据集合称为 **训练集**（training set）。生成模型之后，我们要对模型进行 **测试**（testing），测试所使用的数据集合称为 **测试集**（testing set）。\n",
    "\n",
    "一般来说，我们只有一个包含 m 个样例的数据集 $ D = \\{(\\bf{x_1}, y_1), (\\bf{x_2}, y_2), ..., (\\bf{x_m}, y_m)\\} $，所以得想办法对数据集进行划分，分成训练和测试两类，训练集记为 $ S $，测试集记为 $ T $。这样的划分方法有很多，常见的有：**留出法**（hold-out）、**交叉验证法**（cross validation）、**自助法**（bootstrapping）等。\n",
    "\n",
    "留出法非常简单，直接将数据集划分成两个互斥的集合，分别作为训练集和测试集，$ D = S \\cup T, S \\cap T = \\emptyset $，常见的做法是将大约 2/3 ~ 4/5 的数据用于训练，剩余的数据用于测试，注意划分的时候尽可能保持数据分布的一致性。\n",
    "\n",
    "交叉验证法先将数据集划分成 k 个大小相似的互斥子集，$ D = D_1 \\cup D_2 \\cup \\dots \\cup D_k, D_i \\cap D_j = \\emptyset(i \\ne j) $，同样划分时尽可能保持数据分布的一致性。然后，用其中的 k-1 个子集的并集作为训练集，剩下的那个子集作为测试集，这样可以进行 k 次训练和测试，最终计算这 k 次测试结果的均值。交叉验证法又叫 **k 折交叉验证**（k-fold cross validation）。\n",
    "\n",
    "TODO\n",
    "自助法以自助采样为基础。\n",
    "\n",
    "其实，在前面介绍损失函数时提到了两种损失函数，一种是 **绝对损失（Absolute Loss）**，一种是 **平方损失（Squared Loss）**。\n",
    "\n",
    "绝对损失函数：$$ loss = |y - \\hat{y}| $$\n",
    "\n",
    "平方损失函数：$$ loss = (y - \\hat{y})^2 $$\n",
    "\n",
    "这实际上也是两种评估模型好坏的指标，分别是：**平均绝对误差**（Mean Absolute Error，MAE） 和 **均方误差**（Mean Squared Error，MSE）。\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{N} \\sum_{i=1}^{N} \\left| y_i - \\hat{y_i} \\right|\n",
    "$$\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2\n",
    "$$\n",
    "\n",
    "除此之外，从 MAE 还可以演变成一个新的指标，**平均绝对百分误差**（Mean Absolute Percentage Error，MAPE）：\n",
    "\n",
    "$$\n",
    "MAPE = \\frac{100}{N} \\sum_{i=1}^{N} \\left| \\frac{y_i - \\hat{y_i}}{y_i} \\right|, y_i \\ne 0\n",
    "$$\n",
    "\n",
    "MAPE 通过计算绝对误差的百分比来表示预测效果，其取值越小越好，如果 MAPE = 10，这表明预测平均偏离真实值 10%。\n",
    "\n",
    "从 MSE 也可以演变成一个新的指标，**均方根误差**（Root Mean Squared Error，RMSE），它就是对 MSE 求开方：\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2} = \\sqrt{MSE}\n",
    "$$\n",
    "\n",
    "基于 RMSE 还有一个变种指标，叫**均方根对数误差**（Root Mean Squared Logarithmic Error，RMSLE），将上面公式中的 $y_i$ 和 $\\hat{y_i}$ 换成对数形式：\n",
    "\n",
    "$$\n",
    "RMSLE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (log(y_i+1) - log(\\hat{y_i}+1))^2}\n",
    "$$\n",
    "\n",
    "最后，**$R^2$**（R-Square）也是一个常见的评估指标，它的公式如下：\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{N} (y_i - \\hat{y_i})^2}{\\sum_{i=1}^{N} (y_i - \\bar{y_i})^2}\n",
    "$$\n",
    "\n",
    "$R^2$ 用于度量因变量的变异中可由自变量解释部分所占的比例，一般取值范围是 0~1，$R^2$ 越接近 1，表明回归平方和占总平方和的比例越大，回归线与各观测点越接近，用 x 的变化来解释 y 值变差的部分就越多，回归的拟合程度就越好。\n",
    "\n",
    "#### 参考\n",
    "\n",
    "[一份非常全面的机器学习分类与回归算法的评估指标汇总](https://juejin.im/post/5bbbc1d6f265da0af40726fb)\n",
    "\n",
    "#### TODO\n",
    "\n",
    "* 为什么需要这么多的评估指标？\n",
    "* 每一种评估指标的优缺点，举例说明\n",
    "* 还有没有其他的评估指标？\n",
    "* RMSE 代表的是预测值和真实值差值的样本标准差？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
