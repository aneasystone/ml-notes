{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 课程名称：Python3入门机器学习经典算法与应用\n",
    "* 课程来源：https://coding.imooc.com/\n",
    "* 课程地址：https://coding.imooc.com/class/chapter/169.html\n",
    "* 讲师：liuyubobobo\n",
    "\n",
    "## 第1章 欢迎来到 Python3 玩转机器学习\n",
    "\n",
    "### 1-1 什么是机器学习\n",
    "### 1-2 课程涵盖的内容和理念\n",
    "### 1-3 课程所使用的主要技术栈\n",
    "\n",
    "## 第2章 机器学习基础\n",
    "\n",
    "### 2-1 机器学习世界的数据\n",
    "### 2-2 机器学习的主要任务\n",
    "### 2-3 监督学习，非监督学习，半监督学习和增强学习\n",
    "### 2-4 批量学习，在线学习，参数学习和非参数学习\n",
    "### 2-5 和机器学习相关的“哲学”思考\n",
    "### 2-6 课程使用环境搭建\n",
    "\n",
    "## 第3章 Jupyter Notebook, numpy和matplotlib\n",
    "\n",
    "### 3-1 Jupyter Notebook基础\n",
    "### 3-2 Jupyter Notebook中的魔法命令\n",
    "### 3-3 Numpy数据基础\n",
    "### 3-4 创建Numpy数组(和矩阵)\n",
    "### 3-5 Numpy数组(和矩阵)的基本操作\n",
    "### 3-6 Numpy数组(和矩阵)的合并与分割\n",
    "### 3-7 Numpy中的矩阵运算\n",
    "### 3-8 Numpy中的聚合运算\n",
    "### 3-9 Numpy中的arg运算\n",
    "### 3-10 Numpy中的比较和Fancy Indexing\n",
    "### 3-11 Matplotlib数据可视化基础\n",
    "### 3-12 数据加载和简单的数据探索\n",
    "\n",
    "## 第4章 最基础的分类算法-k近邻算法 kNN\n",
    "\n",
    "### 4-1 k近邻算法基础\n",
    "### 4-2 scikit-learn中的机器学习算法封装\n",
    "### 4-3 训练数据集，测试数据集\n",
    "### 4-4 分类准确度\n",
    "### 4-5 超参数\n",
    "### 4-6 网格搜索与k近邻算法中更多超参数\n",
    "### 4-7 数据归一化\n",
    "### 4-8 scikit-learn中的Scaler\n",
    "### 4-9 更多有关k近邻算法的思考\n",
    "\n",
    "## 第5章 线性回归法\n",
    "\n",
    "### 5-1 简单线性回归\n",
    "### 5-2 最小二乘法\n",
    "### 5-3 简单线性回归的实现\n",
    "### 5-4 向量化\n",
    "### 5-5 衡量线性回归法的指标：MSE，RMSE和MAE\n",
    "### 5-6 最好的衡量线性回归法的指标：R Squared\n",
    "### 5-7 多元线性回归和正规方程解\n",
    "### 5-8 实现多元线性回归\n",
    "### 5-9 使用scikit-learn解决回归问题\n",
    "### 5-10 线性回归的可解释性和更多思考\n",
    "\n",
    "## 第6章 梯度下降法\n",
    "\n",
    "### 6-1 什么是梯度下降法\n",
    "### 6-2 模拟实现梯度下降法\n",
    "### 6-3 线性回归中的梯度下降法\n",
    "### 6-4 实现线性回归中的梯度下降法\n",
    "### 6-5 梯度下降法的向量化和数据标准化\n",
    "### 6-6 随机梯度下降法\n",
    "### 6-7 scikit-learn中的随机梯度下降法\n",
    "### 6-8 如何确定梯度计算的准确性？调试梯度下降法\n",
    "### 6-9 有关梯度下降法的更多深入讨论\n",
    "\n",
    "## 第7章 PCA与梯度上升法\n",
    "\n",
    "### 7-1 什么是PCA\n",
    "### 7-2 使用梯度上升法求解PCA问题\n",
    "### 7-3 求数据的主成分PCA\n",
    "### 7-4 求数据的前n个主成分\n",
    "### 7-5 高维数据映射为低维数据\n",
    "### 7-6 scikit-learn中的PCA\n",
    "### 7-7 试手MNIST数据集\n",
    "### 7-8 使用PCA对数据进行降噪\n",
    "### 7-9 人脸识别与特征脸\n",
    "\n",
    "## 第8章 多项式回归与模型泛化\n",
    "\n",
    "### 8-1 什么是多项式回归\n",
    "### 8-2 scikit-learn中的多项式回归与Pipeline\n",
    "### 8-3 过拟合与欠拟合\n",
    "### 8-4 为什么要有训练数据集与测试数据集\n",
    "### 8-5 学习曲线\n",
    "### 8-6 验证数据集与交叉验证\n",
    "### 8-7 偏差方差平衡\n",
    "### 8-8 模型泛化与岭回归\n",
    "### 8-9 LASSO\n",
    "### 8-10 L1, L2和弹性网络\n",
    "\n",
    "## 第9章 逻辑回归\n",
    "\n",
    "###  9-1 什么是逻辑回归\n",
    "### 9-2 逻辑回归的损失函数\n",
    "### 9-3 逻辑回归损失函数的梯度\n",
    "### 9-4 实现逻辑回归算法\n",
    "### 9-5 决策边界\n",
    "### 9-6 在逻辑回归中使用多项式特征\n",
    "### 9-7 scikit-learn中的逻辑回归\n",
    "### 9-8 OvR与OvO\n",
    "\n",
    "## 第10章 评价分类结果\n",
    "\n",
    "### 10-1 准确度的陷阱和混淆矩阵\n",
    "### 10-2 精准率和召回率\n",
    "### 10-3 实现混淆矩阵，精准率和召回率\n",
    "### 10-4 F1 Score\n",
    "### 10-5 精准率和召回率的平衡\n",
    "### 10-6 精准率-召回率曲线\n",
    "### 10-7 ROC曲线\n",
    "### 10-8 多分类问题中的混淆矩阵\n",
    "\n",
    "## 第11章 支撑向量机 SVM\n",
    "\n",
    "###  11-1 什么是SVM\n",
    "### 11-2 SVM背后的最优化问题\n",
    "### 11-3 Soft Margin SVM\n",
    "### 11-4 scikit-learn中的SVM\n",
    "### 11-5 SVM中使用多项式特征和核函数\n",
    "### 11-6 到底什么是核函数\n",
    "### 11-7 RBF核函数\n",
    "### 11-8 RBF核函数中的gamma\n",
    "### 11-9 SVM思想解决回归问题\n",
    "\n",
    "## 第12章 决策树\n",
    "\n",
    "### 12-1 什么是决策树\n",
    "### 12-2 信息熵\n",
    "### 12-3 使用信息熵寻找最优划分\n",
    "### 12-4 基尼系数\n",
    "### 12-5 CART与决策树中的超参数\n",
    "### 12-6 决策树解决回归问题\n",
    "### 12-7 决策树的局限性\n",
    "\n",
    "## 第13章 集成学习和随机森林\n",
    "\n",
    "### 13-1 什么是集成学习\n",
    "### 13-2 Soft Voting Classifier\n",
    "### 13-3 Bagging 和 Pasting\n",
    "### 13-4 oob (Out-of-Bag) 和关于Bagging的更多讨论\n",
    "### 13-5 随机森林和 Extra-Trees\n",
    "### 13-6 Ada Boosting 和 Gradient Boosting\n",
    "### 13-7 Stacking\n",
    "\n",
    "## 第14章 更多机器学习算法\n",
    "\n",
    "### 14-1 学习scikit-learn文档, 大家加油！\n",
    "### 14-2 学习完这个课程以后怎样继续深入机器学习的学习？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
