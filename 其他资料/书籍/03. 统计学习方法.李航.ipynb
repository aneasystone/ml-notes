{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第 1 章 统计学习方法概论\n",
    "\n",
    "### 1.1 统计学习\n",
    "\n",
    "### 1.2 监督学习\n",
    "\n",
    "#### 1.2.1 基本概念\n",
    "\n",
    "#### 1.2.2 问题的形式化\n",
    "\n",
    "### 1.3 统计学习三要素\n",
    "\n",
    "#### 1.3.1 模型\n",
    "\n",
    "#### 1.3.2 策略\n",
    "\n",
    "#### 1.3.3 算法\n",
    "\n",
    "### 1.4 模型评估与模型选择\n",
    "\n",
    "#### 1.4.1 训练误差与测试误差\n",
    "\n",
    "#### 1.4.2 过拟合与模型模型选择\n",
    "\n",
    "### 1.5 正则化与交叉验证\n",
    "\n",
    "#### 1.5.1 正则化\n",
    "\n",
    "#### 1.5.2 交叉验证\n",
    "\n",
    "### 1.6 泛化能力\n",
    "\n",
    "#### 1.6.1 泛化误差\n",
    "\n",
    "#### 1.6.2 泛化误差上界\n",
    "\n",
    "### 1.7 生成模型与判别模型\n",
    "\n",
    "### 1.8 分类问题\n",
    "\n",
    "### 1.9 标注问题\n",
    "\n",
    "### 1.10 回归问题\n",
    "\n",
    "## 第 2 章 感知机\n",
    "\n",
    "### 2.1 感知机模型\n",
    "\n",
    "### 2.2 感知机学习策略\n",
    "\n",
    "#### 2.2.1 数据集的线性可分\n",
    "\n",
    "#### 2.2.2 感知机学习策略\n",
    "\n",
    "### 2.3 感知机学习算法\n",
    "\n",
    "#### 2.3.1 感知机学习算法的原始形式\n",
    "\n",
    "#### 2.3.2 算法的收敛性\n",
    "\n",
    "#### 2.3.3 感知机学习算法的对偶形式\n",
    "\n",
    "## 第 3 章 k 近邻法\n",
    "\n",
    "### 3.1 k 近邻算法\n",
    "\n",
    "### 3.2 k 近邻模型\n",
    "\n",
    "#### 3.2.1 模型\n",
    "\n",
    "#### 3.2.2 距离度量\n",
    "\n",
    "#### 3.2.3 k 值的选择\n",
    "\n",
    "#### 3.2.4 分类决策规则\n",
    "\n",
    "### 3.3 k 近邻法的实现：kd 树\n",
    "\n",
    "#### 3.3.1 构造 kd 树\n",
    "\n",
    "#### 3.3.2 搜索 kd 树\n",
    "\n",
    "## 第 4 章 朴素贝叶斯法\n",
    "\n",
    "### 4.1 朴素贝叶斯法的学习与分类\n",
    "\n",
    "#### 4.1.1 基本方法\n",
    "\n",
    "#### 4.1.2 后验概率最大化的含义\n",
    "\n",
    "### 4.2 朴素贝叶斯法的参数估计\n",
    "\n",
    "#### 4.2.1 极大似然法\n",
    "\n",
    "#### 4.2.2 学习与分类算法\n",
    "\n",
    "#### 4.2.3 贝叶斯估计\n",
    "\n",
    "## 第 5 章 决策树\n",
    "\n",
    "### 5.1 决策树模型与学习\n",
    "\n",
    "#### 5.1.1 决策树模型\n",
    "\n",
    "#### 5.1.2 决策树与 if-then 规则\n",
    "\n",
    "#### 5.1.3 决策树与条件概率分布\n",
    "\n",
    "#### 5.1.4 决策树学习\n",
    "\n",
    "### 5.2 特征选择\n",
    "\n",
    "#### 5.2.1 特征选择问题\n",
    "\n",
    "#### 5.2.2 信息增益\n",
    "\n",
    "#### 5.2.3 信息增益比\n",
    "\n",
    "### 5.3 决策树的生成\n",
    "\n",
    "#### 5.3.1 ID3 算法\n",
    "\n",
    "#### 5.3.2 C4.5 的生成算法\n",
    "\n",
    "### 5.4 决策树的剪枝\n",
    "\n",
    "### 5.5 CART 算法\n",
    "\n",
    "#### 5.5.1 CART 生成\n",
    "\n",
    "#### 5.5.2 CART 剪枝\n",
    "\n",
    "## 第 6 章 逻辑斯蒂回归与最大熵模型\n",
    "\n",
    "### 6.1 逻辑斯蒂回归模型\n",
    "\n",
    "#### 6.1.1 逻辑斯蒂分布\n",
    "\n",
    "#### 6.1.2 二项逻辑斯蒂回归模型\n",
    "\n",
    "#### 6.1.3 模型参数估计\n",
    "\n",
    "#### 6.1.4 多项逻辑斯蒂回归\n",
    "\n",
    "### 6.2 最大熵模型\n",
    "\n",
    "#### 6.2.1 最大熵原理\n",
    "\n",
    "#### 6.2.2 最大熵模型的定义\n",
    "\n",
    "#### 6.2.3 最大熵模型的学习\n",
    "\n",
    "#### 6.2.4 极大似然估计\n",
    "\n",
    "### 6.3 模型学习的最优化算法\n",
    "\n",
    "#### 6.3.1 改进的迭代尺度法\n",
    "\n",
    "#### 6.3.2 拟牛顿法\n",
    "\n",
    "## 第 7 章 支持向量机\n",
    "\n",
    "### 7.1 线性可分支持向量机与硬间隔最大化\n",
    "\n",
    "#### 7.1.1 线性可分支持向量机\n",
    "\n",
    "#### 7.1.2 函数间隔和几何间隔\n",
    "\n",
    "#### 7.1.3 间隔最大化\n",
    "\n",
    "#### 7.1.4 学习的对偶算法\n",
    "\n",
    "### 7.2 线性支持向量机与软间隔最大化\n",
    "\n",
    "#### 7.2.1 线性支持向量机\n",
    "\n",
    "#### 7.2.2 学习的对偶算法\n",
    "\n",
    "#### 7.2.3 支持向量\n",
    "\n",
    "#### 7.2.4 合页损失函数\n",
    "\n",
    "### 7.3 非线性支持向量机与核函数\n",
    "\n",
    "#### 7.3.1 核技巧\n",
    "\n",
    "#### 7.3.2 正定核\n",
    "\n",
    "#### 7.3.3 常用核函数\n",
    "\n",
    "#### 7.3.4 非线性支持向量分类机\n",
    "\n",
    "### 7.4 序列最小最优化算法\n",
    "\n",
    "#### 7.4.1 两个变量二次规划的求解方法\n",
    "\n",
    "#### 7.4.2 变量的选择方法\n",
    "\n",
    "#### 7.4.3 SMO 算法\n",
    "\n",
    "## 第 8 章 提升方法\n",
    "\n",
    "### 8.1 提升方法 AdaBoost 算法\n",
    "\n",
    "#### 8.1.1 提升方法的基本思路\n",
    "\n",
    "#### 8.1.2 AdaBoost 算法\n",
    "\n",
    "#### 8.1.3 AdaBoost 的例子\n",
    "\n",
    "### 8.2 AdaBoost 算法的训练误差分析\n",
    "\n",
    "### 8.3 AdaBoost 算法的解释\n",
    "\n",
    "#### 8.3.1 前向分步算法\n",
    "\n",
    "#### 8.3.2 前向分步算法与 AdaBoost\n",
    "\n",
    "### 8.4 提升树\n",
    "\n",
    "#### 8.4.1 提升树模型\n",
    "\n",
    "#### 8.4.2 提升树算法\n",
    "\n",
    "#### 8.4.3 梯度提升\n",
    "\n",
    "## 第 9 章 EM 算法及其推广\n",
    "\n",
    "### 9.1 EM 算法的引入\n",
    "\n",
    "#### 9.1.1 EM 算法\n",
    "\n",
    "#### 9.1.2 EM 算法的导出\n",
    "\n",
    "#### 9.1.3 EM 算法在非监督学习中的应用\n",
    "\n",
    "### 9.2 EM 算法的收敛性\n",
    "\n",
    "### 9.3 EM 算法在高斯混合模型学习中的应用\n",
    "\n",
    "#### 9.3.1 高斯混合模型\n",
    "\n",
    "#### 9.3.2 高斯混合模型参数估计的 EM 算法\n",
    "\n",
    "### 9.4 EM 算法的推广\n",
    "\n",
    "#### 9.4.1 F 函数的极大-极大算法\n",
    "\n",
    "#### 9.4.2 GEM 算法\n",
    "\n",
    "## 第 10 章 隐马尔可夫模型\n",
    "\n",
    "### 10.1 隐马尔可夫模型的基本概念\n",
    "\n",
    "#### 10.1.1 隐马尔可夫模型的定义\n",
    "\n",
    "#### 10.1.2 观测序列的生成模型\n",
    "\n",
    "#### 10.1.3 隐马尔可夫模型的 3 个基本问题\n",
    "\n",
    "### 10.2 概率计算算法\n",
    "\n",
    "#### 10.2.1 直接计算法\n",
    "\n",
    "#### 10.2.2 前向算法\n",
    "\n",
    "#### 10.2.3 后向算法\n",
    "\n",
    "#### 10.2.4 一些概率与期望值的计算\n",
    "\n",
    "### 10.3 学习算法\n",
    "\n",
    "#### 10.3.1 监督学习方法\n",
    "\n",
    "#### 10.3.2 Baum-Welch 算法\n",
    "\n",
    "#### 10.3.3 Baum-Welch 模型参数估计公式\n",
    "\n",
    "### 10.4 预测算法\n",
    "\n",
    "#### 10.4.1 近似算法\n",
    "\n",
    "#### 10.4.2 维特比算法\n",
    "\n",
    "## 第 11 章 条件随机场\n",
    "\n",
    "### 11.1 概率无向图模型\n",
    "\n",
    "#### 11.1.1 模型定义\n",
    "\n",
    "#### 11.1.2 概率无向图模型的因子分解\n",
    "\n",
    "### 11.2 条件随机场的定义与形式\n",
    "\n",
    "#### 11.2.1 条件随机场的定义\n",
    "\n",
    "#### 11.2.2 条件随机场的参数化形式\n",
    "\n",
    "#### 11.2.3 条件随机场的简化形式\n",
    "\n",
    "#### 11.2.4 条件随机场的矩阵形式\n",
    "\n",
    "### 11.3 条件随机场的概率计算问题\n",
    "\n",
    "#### 11.3.1 前向-后向算法\n",
    "\n",
    "#### 11.3.2 概率计算\n",
    "\n",
    "#### 11.3.3 期望值的计算\n",
    "\n",
    "### 11.4 条件随机场的学习算法\n",
    "\n",
    "#### 11.4.1 改进的迭代尺度法\n",
    "\n",
    "#### 11.4.2 拟牛顿法\n",
    "\n",
    "### 11.5 条件随机场的预测算法\n",
    "\n",
    "## 第 12 章 统计学习方法总结\n",
    "\n",
    "## 附录 A 梯度下降法\n",
    "\n",
    "## 附录 B 牛顿法和拟牛顿法\n",
    "\n",
    "## 附录 C 拉格朗日对偶性"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
