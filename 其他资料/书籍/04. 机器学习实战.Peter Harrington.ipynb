{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一部分　分类\n",
    "\n",
    "## 第1章　机器学习基础\n",
    "\n",
    "### 1.1 　何谓机器学习\n",
    "#### 1.1.1 　传感器和海量数据\n",
    "#### 1.1.2 　机器学习非常重要\n",
    "### 1.2 　关键术语\n",
    "### 1.3 　机器学习的主要任务\n",
    "### 1.4 　如何选择合适的算法\n",
    "### 1.5 　开发机器学习应用程序的步骤\n",
    "### 1.6 　Python语言的优势\n",
    "#### 1.6.1 　可执行伪代码\n",
    "#### 1.6.2 　Python比较流行\n",
    "#### 1.6.3 　Python语言的特色\n",
    "#### 1.6.4 　Python语言的缺点\n",
    "### 1.7 　NumPy函数库基础\n",
    "### 1.8 　本章小结\n",
    "\n",
    "## 第2章　k-近邻算法\n",
    "\n",
    "### 2.1 　k-近邻算法概述\n",
    "#### 2.1.1 　准备：使用Python导入数据\n",
    "#### 2.1.2 　从文本文件中解析数据\n",
    "#### 2.1.3 　如何测试分类器\n",
    "### 2.2 　示例：使用k-近邻算法改进约会网站的配对效果\n",
    "#### 2.2.1 　准备数据：从文本文件中解析数据\n",
    "#### 2.2.2 　分析数据：使用Matplotlib创建散点图\n",
    "#### 2.2.3 　准备数据：归一化数值\n",
    "#### 2.2.4 　测试算法：作为完整程序验证分类器\n",
    "#### 2.2.5 　使用算法：构建完整可用系统\n",
    "### 2.3 　示例：手写识别系统\n",
    "#### 2.3.1 　准备数据：将图像转换为测试向量\n",
    "#### 2.3.2 　测试算法：使用k-近邻算法识别手写数字\n",
    "### 2.4 　本章小结\n",
    "\n",
    "## 第3章　决策树\n",
    "\n",
    "### 3.1 　决策树的构造\n",
    "#### 3.1.1 　信息增益\n",
    "#### 3.1.2 　划分数据集\n",
    "#### 3.1.3 　递归构建决策树\n",
    "### 3.2 　在Python中使用Matplotlib注解绘制树形图\n",
    "#### 3.2.1 　Matplotlib注解\n",
    "#### 3.2.2 　构造注解树\n",
    "### 3.3 　测试和存储分类器\n",
    "#### 3.3.1 　测试算法：使用决策树执行分类\n",
    "#### 3.3.2 　使用算法：决策树的存储\n",
    "### 3.4 　示例：使用决策树预测隐形眼镜类型\n",
    "### 3.5 　本章小结\n",
    "\n",
    "## 第4章　基于概率论的分类方法：朴素贝叶斯\n",
    "\n",
    "### 4.1 　基于贝叶斯决策理论的分类方法\n",
    "### 4.2 　条件概率\n",
    "### 4.3 　使用条件概率来分类\n",
    "### 4.4 　使用朴素贝叶斯进行文档分类\n",
    "### 4.5 　使用Python进行文本分类\n",
    "#### 4.5.1 　准备数据：从文本中构建词向量\n",
    "#### 4.5.2 　训练算法：从词向量计算概率\n",
    "#### 4.5.3 　测试算法：根据现实情况修改分类器\n",
    "#### 4.5.4 　准备数据：文档词袋模型\n",
    "### 4.6 　示例：使用朴素贝叶斯过滤垃圾邮件\n",
    "#### 4.6.1 　准备数据：切分文本\n",
    "#### 4.6.2 　测试算法：使用朴素贝叶斯进行交叉验证\n",
    "### 4.7 　示例：使用朴素贝叶斯分类器从个人广告中获取区域倾向\n",
    "#### 4.7.1 　收集数据：导入RSS源\n",
    "#### 4.7.2 　分析数据：显示地域相关的用词\n",
    "### 4.8 　本章小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第5章　Logistic回归\n",
    "\n",
    "在这一节我们将首次接触最优化问题和算法。\n",
    "\n",
    "### 5.1 　基于Logistic回归和Sigmoid函数的分类\n",
    "\n",
    "对于二分类问题，通常使用 **海维塞德阶跃函数**（Heaviside step function）作为预测函数，也称为 **单位阶跃函数**，但是该函数在跳跃点上从 0 瞬间跳跃到 1，不是一个连续函数，所以使用 **Sigmoid 函数** 来近似。\n",
    "\n",
    "### 5.2 　基于最优化方法的最佳回归系数确定\n",
    "\n",
    "#### 5.2.1 　梯度上升法\n",
    "\n",
    "梯度算法的迭代公式：\n",
    "\n",
    "$$\n",
    "w := w + \\alpha \\nabla_w f(w)\n",
    "$$\n",
    "\n",
    "梯度上升法用来求函数的最大值，梯度下降法用来求函数的最小值。\n",
    "\n",
    "#### 5.2.2 　训练算法：使用梯度上升找到最佳参数\n",
    "#### 5.2.3 　分析数据：画出决策边界\n",
    "#### 5.2.4 　训练算法：随机梯度上升\n",
    "### 5.3 　示例：从疝气病症预测病马的死亡率\n",
    "#### 5.3.1 　准备数据：处理数据中的缺失值\n",
    "#### 5.3.2 　测试算法：用Logistic回归进行分类\n",
    "### 5.4 　本章小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第6章　支持向量机\n",
    "\n",
    "### 6.1 　基于最大间隔分隔数据\n",
    "### 6.2 　寻找最大间隔\n",
    "#### 6.2.1 　分类器求解的优化问题\n",
    "#### 6.2.2 　SVM应用的一般框架\n",
    "### 6.3 　SMO高效优化算法\n",
    "#### 6.3.1 　Platt的SMO算法\n",
    "#### 6.3.2 　应用简化版SMO算法处理小规模数据集\n",
    "### 6.4 　利用完整Platt SMO算法加速优化\n",
    "### 6.5 　在复杂数据上应用核函数\n",
    "#### 6.5.1 　利用核函数将数据映射到高维空间\n",
    "#### 6.5.2 　径向基核函数\n",
    "#### 6.5.3 　在测试中使用核函数\n",
    "### 6.6 　示例：手写识别问题回顾\n",
    "### 6.7 　本章小结\n",
    "\n",
    "## 第7章　利用AdaBoost元算法提高分类性能\n",
    "\n",
    "### 7.1 　基于数据集多重抽样的分类器\n",
    "#### 7.1.1 　bagging：基于数据随机重抽样的分类器构建方法\n",
    "#### 7.1.2 　boosting\n",
    "### 7.2 　训练算法：基于错误提升分类器的性能\n",
    "### 7.3 　基于单层决策树构建弱分类器\n",
    "### 7.4 　完整AdaBoost算法的实现\n",
    "### 7.5 　测试算法：基于AdaBoost的分类\n",
    "### 7.6 　示例：在一个难数据集上应用AdaBoost\n",
    "### 7.7 　非均衡分类问题\n",
    "#### 7.7.1 　其他分类性能度量指标：正确率、召回率及ROC曲线\n",
    "#### 7.7.2 　基于代价函数的分类器决策控制\n",
    "#### 7.7.3 　处理非均衡问题的数据抽样方法\n",
    "### 7.8 　本章小结\n",
    "\n",
    "# 第二部分　利用回归预测数值型数据\n",
    "\n",
    "## 第8章　预测数值型数据：回归\n",
    "\n",
    "### 8.1 　用线性回归找到最佳拟合直线\n",
    "### 8.2 　局部加权线性回归\n",
    "### 8.3 　示例：预测鲍鱼的年龄\n",
    "### 8.4 　缩减系数来“理解”数据\n",
    "#### 8.4.1 　岭回归\n",
    "#### 8.4.2 　lasso\n",
    "#### 8.4.3 　前向逐步回归\n",
    "### 8.5 　权衡偏差与方差\n",
    "### 8.6 　示例：预测乐高玩具套装的价格\n",
    "#### 8.6.1 　收集数据：使用Google购物的API\n",
    "#### 8.6.2 　训练算法：建立模型\n",
    "### 8.7 　本章小结\n",
    "\n",
    "## 第9章　树回归\n",
    "\n",
    "### 9.1 　复杂数据的局部性建模\n",
    "### 9.2 　连续和离散型特征的树的构建\n",
    "### 9.3 　将CART算法用于回归\n",
    "#### 9.3.1 　构建树\n",
    "#### 9.3.2 　运行代码\n",
    "### 9.4 　树剪枝\n",
    "#### 9.4.1 　预剪枝\n",
    "#### 9.4.2 　后剪枝\n",
    "### 9.5 　模型树\n",
    "### 9.6 　示例：树回归与标准回归的比较\n",
    "### 9.7 　使用Python的Tkinter库创建GUI\n",
    "#### 9.7.1 　用Tkinter创建GUI\n",
    "#### 9.7.2 　集成Matplotlib和Tkinter\n",
    "### 9.8 　本章小结\n",
    "\n",
    "# 第三部分　无监督学习\n",
    "\n",
    "## 第10章　利用K-均值聚类算法对未标注数据分组\n",
    "\n",
    "### 10.1 　K-均值聚类算法\n",
    "### 10.2 　使用后处理来提高聚类性能\n",
    "### 10.3 　二分K-均值算法\n",
    "### 10.4 　示例：对地图上的点进行聚类\n",
    "#### 10.4.1 　Yahoo! PlaceFinder API\n",
    "#### 10.4.2 　对地理坐标进行聚类\n",
    "### 10.5 　本章小结\n",
    "\n",
    "## 第11章　使用Apriori算法进行关联分析\n",
    "\n",
    "### 11.1 　关联分析\n",
    "### 11.2 　Apriori原理\n",
    "### 11.3 　使用Apriori算法来发现频繁集\n",
    "#### 11.3.1 　生成候选项集\n",
    "#### 11.3.2 　组织完整的Apriori算法\n",
    "### 11.4 　从频繁项集中挖掘关联规则\n",
    "### 11.5 　示例：发现国会投票中的模式\n",
    "#### 11.5.1 　收集数据：构建美国国会投票记录的事务数据集\n",
    "#### 11.5.2 　测试算法：基于美国国会投票记录挖掘关联规则\n",
    "### 11.6 　示例：发现毒蘑菇的相似特征\n",
    "### 11.7 　本章小结\n",
    "\n",
    "## 第12章　使用FP-growth算法来高效发现频繁项集\n",
    "\n",
    "### 12.1 　FP树：用于编码数据集的有效方式\n",
    "### 12.2 　构建FP树\n",
    "#### 12.2.1 　创建FP树的数据结构\n",
    "#### 12.2.2 　构建FP树\n",
    "### 12.3 　从一棵FP树中挖掘频繁项集\n",
    "#### 12.3.1 　抽取条件模式基\n",
    "#### 12.3.2 　创建条件FP树\n",
    "### 12.4 　示例：在Twitter源中发现一些共现词\n",
    "### 12.5 　示例：从新闻网站点击流中挖掘\n",
    "### 12.6 　本章小结\n",
    "\n",
    "# 第四部分　其他工具\n",
    "\n",
    "## 第13章　利用PCA来简化数据\n",
    "\n",
    "### 13.1 　降维技术\n",
    "### 13.2 　PCA\n",
    "#### 13.2.1 　移动坐标轴\n",
    "#### 13.2.2 　在NumPy中实现PCA\n",
    "### 13.3 　示例：利用PCA对半导体制造数据降维\n",
    "### 13.4 　本章小结\n",
    "\n",
    "## 第14章　利用SVD简化数据\n",
    "\n",
    "### 14.1 　SVD的应用\n",
    "#### 14.1.1 　隐性语义索引\n",
    "#### 14.1.2 　推荐系统\n",
    "### 14.2 　矩阵分解\n",
    "### 14.3 　利用Python实现SVD\n",
    "### 14.4 　基于协同过滤的推荐引擎\n",
    "#### 14.4.1 　相似度计算\n",
    "#### 14.4.2 　基于物品的相似度还是基于用户的相似度？\n",
    "#### 14.4.3 　推荐引擎的评价\n",
    "### 14.5 　示例：餐馆菜肴推荐引擎\n",
    "#### 14.5.1 　推荐未尝过的菜肴\n",
    "#### 14.5.2 　利用SVD提高推荐的效果\n",
    "#### 14.5.3 　构建推荐引擎面临的挑战\n",
    "### 14.6 　基于SVD的图像压缩\n",
    "### 14.7 　本章小结\n",
    "\n",
    "## 第15章　大数据与MapReduce\n",
    "\n",
    "### 15.1 　MapReduce：分布式计算的框架\n",
    "### 15.2 　Hadoop流\n",
    "#### 15.2.1 　分布式计算均值和方差的mapper\n",
    "#### 15.2.2 　分布式计算均值和方差的reducer\n",
    "### 15.3 　在Amazon网络服务上运行Hadoop程序\n",
    "#### 15.3.1 　AWS上的可用服务\n",
    "#### 15.3.2 　开启Amazon网络服务之旅\n",
    "#### 15.3.3 　在EMR上运行Hadoop作业\n",
    "### 15.4 　MapReduce上的机器学习\n",
    "### 15.5 　在Python中使用mrjob来自动化MapReduce\n",
    "#### 15.5.1 　mrjob与EMR的无缝集成\n",
    "#### 15.5.2 　mrjob的一个MapReduce脚本剖析\n",
    "### 15.6 　示例：分布式SVM的Pegasos算法\n",
    "#### 15.6.1 　Pegasos算法\n",
    "#### 15.6.2 　训练算法：用mrjob实现MapReduce版本的SVM\n",
    "### 15.7 　你真的需要MapReduce吗？\n",
    "### 15.8 　本章小结\n",
    "\n",
    "## 附录A 　Python入门\n",
    "\n",
    "## 附录B 　线性代数\n",
    "\n",
    "## 附录C 　概率论复习\n",
    "\n",
    "## 附录D 　资源"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
