{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在决策树学习中，为了尽可能正确地分类训练样本，节点划分过程将不断重复，有时会造成决策树分支过多，从而导致过拟合。解决过拟合通常使用 **剪枝**（pruning）策略，剪枝一般又可以分为 **预剪枝**（prepruning）和 **后剪枝**（postpruning）。\n",
    "\n",
    "### 预剪枝\n",
    "\n",
    "预剪枝是指在决策树生成过程中，对每一个节点在划分前先进行估计，若当前节点的划分不能带来泛化性能的提升，则停止划分，并将当前节点标记为叶节点。\n",
    "\n",
    "如何判定决策树的泛化性能是否提升呢？通常将数据集划分为训练集和验证集两部分，使用训练集训练数据，使用验证集进行性能评估。\n",
    "\n",
    "预剪枝本质上是一种贪心算法，可以禁止很多分支展开，不仅降低了过拟合的风险，而且减少了决策树训练时间开销和测试时间开销；不过，它有可能会欠拟合。\n",
    "\n",
    "### 后剪枝\n",
    "\n",
    "后剪枝是指先从训练集生成一颗完整的决策树，然后**自底向上**的对非叶节点进行考察，若将该节点对应的子树替换为叶节点能提升决策树的泛化性能，则将该子树替换为叶节点。\n",
    "\n",
    "一般情况下，后剪枝欠拟合的风险很小，泛化性能优于预剪枝；但后剪枝过程是在生成一颗完整的决策树之后进行的，而且要自底向上对树中所有非叶节点进行考察，因此训练时间开销要大得多。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
