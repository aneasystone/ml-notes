{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前面的例子中，我们假定样本空间是线性可分的，即存在一个超平面将不同类别完全划分开来。然而在现实的分类任务中，样本空间往往是线性不可分的，譬如下面这样：\n",
    "\n",
    "![](../../images/svm-unseparable.png)\n",
    "\n",
    "可见，数据中混入了一些异常点，导致没办法通过一个超平面将其分成两个部分。解决这个问题的一个办法是，允许支持向量机在一些样本上出错。在前面介绍支持向量机的基本形式时，我们要求所有的样本都满足下面的约束条件：\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "w^Tx_i + b \\ge +1, y_i = +1 \\\\\n",
    "w^Tx_i + b \\le -1, y_i = -1\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "也可以简写成：\n",
    "\n",
    "$$\n",
    "y_i(w^Tx_i + b) - 1 \\ge 0\n",
    "$$\n",
    "\n",
    "这个约束条件确保所有样本都被正确划分，这被称为 **硬间隔**（hard margin），我们把这个约束条件稍微放宽，允许某些样本不满足该条件，得到的就是 **软间隔**（soft margin），当然，我们希望不满足约束条件的样本越少越好。\n",
    "\n",
    "我们在优化目标中加入 **0/1损失函数** $\\ell_{0/1}$：\n",
    "\n",
    "$$\n",
    "\\mathop \\min_{w,b} \\frac{1}{2}\\|w\\|^2 + C \\sum_{i=1}^m \\ell_{0/1}(y_i(w^Tx_i + b) - 1)\n",
    "$$\n",
    "\n",
    "其中，\n",
    "\n",
    "$$\n",
    "\\ell_{0/1}(z) =\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "0, z \\geq 0 \\\\\n",
    "1, z < 0 \\\\\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "这里的 C 是一个超参数，决定了你有多重视异常点带来的损失。显然，当 C 为无穷大时，为了求优化目标的最小值，这里加上的 0/1 损失函数类似于惩罚项，会迫使所有的样本都满足约束 $y_i(w^Tx_i + b) - 1 \\ge 0$，这就和硬间隔一样；当 C 为某一常数时，允许某些样本不满足约束，得到的就是软间隔。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// 替代损失函数\n",
    "\n",
    "// 松弛变量\n",
    "\n",
    "// 对偶问题"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
