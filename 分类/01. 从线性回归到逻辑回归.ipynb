{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归一般用于连续型模型的回归问题，若要解决分类问题，可以转化为 **逻辑回归**（logistic regression， 又称 **对数回归**）。虽然名字里面有回归，但其实是一种分类算法，不仅能够预测“类别”，还能给出近似的概率预测。\n",
    "\n",
    "### 线性回归回顾\n",
    "\n",
    "我们先回顾一下线性回归问题，线性模型一般表示成：\n",
    "\n",
    "$$\n",
    "h(x) = h_\\theta(x) = \\theta_0 + \\theta_1x_1 + ... + \\theta_dx_d\n",
    "$$\n",
    "\n",
    "也可以写成向量表示：\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\Theta^TX\n",
    "$$\n",
    "\n",
    "最常用的求解方法是 **最小二乘法**，它采用 **平方损失** 作为损失函数：\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "要求解的模型参数就是损失函数取最小值时参数取值：\n",
    "\n",
    "$$\n",
    "\\theta = \\min_{\\theta} J_\\theta\n",
    "$$\n",
    "\n",
    "最小二乘法有两种常见的求解思路，一种使用正规方程：\n",
    "\n",
    "$$\n",
    "\\Theta = (X^TX)^{-1}X^Ty\n",
    "$$\n",
    "\n",
    "另一种使用优化算法梯度下降：\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha(y^{(i)} - h_\\theta(x^{(i)}))x_j^{(i)}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
