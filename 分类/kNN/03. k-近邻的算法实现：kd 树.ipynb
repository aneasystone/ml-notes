{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据前面的学习，我们知道实现 k-近邻算法的关键就是如何找到距离某个样本最近的 k 个样本。最简单的实现方法是线性扫描（linear scan），或者叫做暴力搜索，也就是依次计算输入样本和每个训练样本的距离，不过当训练集非常大时，这种计算非常耗时，是行不通的。\n",
    "\n",
    "为了提高 k-近邻搜索的效率，人们想出了很多特殊的数据结构存储训练数据，以减少计算距离的次数，其中 **kd 树**（kd tree）是最基础，也是最重要的一种。它的基本思想是对搜索空间进行层次划分，将整个空间划分为特定的几个部分，然后在特定空间的部分内进行搜索操作。如果划分空间没有重叠，这种情况叫做 **Clipping**，其代表算法就是 kd 树；如果划分空间有重叠，这种情况叫 **Overlapping**，其代表算法是 R 树。\n",
    "\n",
    "### 什么是 kd 树\n",
    "\n",
    "kd 树的概念是斯坦福大学 Jon Louis Bentley 于 1975 年在 ACM 杂志上发表的一篇论文 **Multidimensional Binary Search Trees Used for Associative Searching** 中正式提出的。它是 K-dimension tree 的缩写。\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/23966698\n",
    "\n",
    "https://blog.sengxian.com/algorithms/k-dimensional-tree\n",
    "\n",
    "https://www.jianshu.com/p/ffe52db3e12b\n",
    "\n",
    "https://wuzhiwei.net/kdtree/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
