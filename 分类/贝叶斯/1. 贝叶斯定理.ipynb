{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件概率\n",
    "\n",
    "**概率**（probability）是从随机试验中的事件到实数域的映射函数，用于表示事件发生的可能性，事件 $A$ 发生的概率通常记为 $P(A)$。\n",
    "\n",
    "如果 $A$ 和 $B$ 是样本空间 $\\Omega$ 上的两个事件，且 $P(B) > 0$，那么在给定 $B$ 时 $A$ 的**条件概率**（conditional probability）为：\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac {P(A \\cap B)}{P(B)}\n",
    "$$\n",
    "\n",
    "$P(A|B)$ 表示在事件 $B$ 发生的条件下，事件 $A$ 发生的概率。\n",
    "\n",
    "同理可得：\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac {P(A \\cap B)}{P(A)}\n",
    "$$\n",
    "\n",
    "结合上面两个公式，得到概率的**乘法定理**（也叫乘法法则）：\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(A)P(B|A) = P(B)P(A|B)\n",
    "$$\n",
    "\n",
    "### 独立事件\n",
    "\n",
    "在条件概率中，如果事件 A 和 B 是相互独立的，也就是说事件 A 的发生和事件 B 没有任何关系，我们有：\n",
    "\n",
    "$$\n",
    "P(A|B) = P(A)\n",
    "$$\n",
    "\n",
    "上面的式子也可以解释成，无论事件 B 有没有发生，事件 A 发生的概率都不变。于是对于独立事件，我们得到一个很重要的公式，这个公式是 **朴素贝叶斯**（naive Bayes）的前提：\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(A)P(B)\n",
    "$$\n",
    "\n",
    "推广到一般形式：\n",
    "\n",
    "$$\n",
    "P(A_1 \\cap A_2 \\cap \\dots \\cap A_n) = P(A_1)P(A_2) \\dots P(A_n)\n",
    "$$\n",
    "\n",
    "### 全概率公式\n",
    "\n",
    "上面我们假设 $A$ 是样本空间 $\\Omega$ 上的一个事件，我们把这个事件的对立事件记为 $\\bar{A}$，很显然，样本空间是 $A$ 和 $\\bar{A}$ 两个事件之和。于是，事件 $B$ 的概率可以写成下面这样：\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(B) &= P(B \\cap A) + P(B \\cap \\bar{A}) \\\\\n",
    "&= P(B|A)P(A) + P(B|\\bar{A})P(\\bar{A})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "这就是**全概率公式**。这个公式可以推广到一般形式，假设 $A_1, A_2, ..., A_n$ 是样本空间 $\\Omega$ 的一个划分，即 $\\sum_{i=1}^nA_i = \\Omega$，并且 $A_i$ 互不相交，则有：\n",
    "\n",
    "$$\n",
    "P(B) = \\sum_{i=1}^n P(B|A_i)P(A_i)\n",
    "$$\n",
    "\n",
    "### 贝叶斯定理\n",
    "\n",
    "根据上面概率的乘法定理，可以得到下面的公式：\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "这个公式被称为 **贝叶斯公式**，也叫 **贝叶斯法则** 或 **贝叶斯定理**（Bayesian theorem），它是英国数学家托马斯·贝叶斯（Thomas Bayes）在1763年提出的，这个公式可以用于条件概率的求解。\n",
    "\n",
    "推广到一般形式，我们可以把样本空间划分成 $A_1, A_2, ..., A_n$，根据前面的全概率公式，则可以计算出每个划分 $A_i$ 的条件概率：\n",
    "\n",
    "$$\n",
    "P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{i=1}^n P(B|A_i)P(A_i)}\n",
    "$$\n",
    "\n",
    "在上面的公式中，$P(A_i)$ 是在事件 B 发生之前 $A_i$ 的概率，所以叫做 **先验概率**（Prior probability）或 **边缘概率**，而 $P(A_i|B)$ 指的是事件 B 发生后，对 $A_i$ 的概率进行修正，我们把它叫做 **后验概率**（Posterior probability），$P(B|A_i)$ 叫做 **类条件概率**（class-conditional probability）或 **似然**（Likelihood）。\n",
    "\n",
    "### 朴素贝叶斯分类器\n",
    "\n",
    "在上面的贝叶斯公式中，我们可以把 $A_i$ 当作类标记，这里的样本空间被划分成 $A_1, A_2, ..., A_n$，可以理解为样本空间可以分成 n 类，我们可以把 $B$ 当作样本数据的特征向量。类标记集合 $\\mathcal{Y} = \\{c_1, c_2, \\dots, c_K\\}$，输入为特征向量 $x$，输出为类标记 $y$，那么贝叶斯公式可以改成下面的形式：\n",
    "\n",
    "$$\n",
    "P(Y=c_k|X=x) = \\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_{i=1}^n P(X=x|Y=c_k)P(Y=c_k)}\n",
    "$$\n",
    "\n",
    "通过这个公式，可以计算出输入特征 $X$ 属于类别 $c_k$ 的概率，计算所有类别的概率，看看哪个类别的概率最大，就把输入特征归到这个类别，这就是**贝叶斯分类器**（Bayes classifier）的基本原理。\n",
    "\n",
    "// TODO\n",
    "\n",
    "### 贝叶斯推断"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
