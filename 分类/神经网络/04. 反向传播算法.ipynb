{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上一节中，我们构造了三个两层神经网络来解决 AND、OR、NOT 问题，并构造了一个三层神经网络来解决 XOR 问题，那么这些神经网络结构是如何构造出来的呢？神经元之间的权重和每个神经元的阈值又是如何确定的呢？如果是线性可分问题，两层神经网络就可以解决，这也就是感知机模型，通过前面学习的随机梯度下降法来训练感知机即可求解，如果是线性不可分问题，需要构造更复杂的多层网络结构，通常使用 **反向传播算法**（error BackPropagation，简称 **BP 算法**，也叫做 **误差逆传播算法**）。\n",
    "\n",
    "### 神经网络的符号表示\n",
    "\n",
    "假设我们要求解的神经网络如下图所示：\n",
    "\n",
    "<img src=\"../../images/bp-method.png\" width=\"800px\" />\n",
    "\n",
    "该神经网络的特点如下：\n",
    "\n",
    "* 输入层有 $d$ 个节点，表示输入的特征向量为 $d$ 维\n",
    "* 输出层有 $l$ 个节点，表示输出向量为 $l$ 维，也就是 $l$ 类分类问题，$l = 2$ 时就是二分类问题\n",
    "* 隐层有 $q$ 个节点\n",
    "* 第 $i$ 个输入层神经元和第 $h$ 个隐层神经元之间的连接权重为 $v_{ih}$\n",
    "* 第 $h$ 个隐层神经元的阈值为 $\\gamma_h$\n",
    "* 第 $h$ 个隐层神经元和第 $j$ 个输出层神经元之间的连接权重为 $w_{hj}$\n",
    "* 第 $j$ 个输出层神经元的阈值为 $\\theta_j$\n",
    "\n",
    "所以有，第 $h$ 个隐层神经元接受到的输入为：\n",
    "\n",
    "$$\n",
    "\\alpha_h = v_{1h}x_1 + v_{2h}x_2 + \\dots + v_{dh}x_d = \\sum_{i=1}^d v_{ih}x_i\n",
    "$$\n",
    "\n",
    "它的输出为：\n",
    "\n",
    "$$\n",
    "b_h = f(\\alpha_h - \\gamma_h)\n",
    "$$\n",
    "\n",
    "最后得到，第 $j$ 个输出层神经元的输入为：\n",
    "\n",
    "$$\n",
    "\\beta_j = w_{1j}b_1 + w_{2j}b_2 + \\dots + w_{qj}b_q = \\sum_{h=1}^q w_{hj}b_h\n",
    "$$\n",
    "\n",
    "它的输出为：\n",
    "\n",
    "$$\n",
    "y_j = f(\\beta_j - \\theta_j)\n",
    "$$\n",
    "\n",
    "### 神经网络的损失函数\n",
    "\n",
    "标准BP算法 vs. 累积BP算法\n",
    "\n",
    "### BP算法的推导\n",
    "\n",
    "### 过拟合"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
